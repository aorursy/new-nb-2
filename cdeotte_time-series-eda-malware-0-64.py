# IMPORT LIBRARIES
import pandas as pd, numpy as np, os
import matplotlib.pyplot as plt
from datetime import datetime

# VARIABLES TO IMPORT
vv = ['AVProductStatesIdentifier','AVProductsInstalled','OsBuild',
       'CountryIdentifier','Processor','SmartScreen','Census_OSVersion',
       'Census_ProcessorCoreCount','Census_ProcessorModelIdentifier', 
       'Census_HasOpticalDiskDrive','Census_TotalPhysicalRAM',
       'Census_InternalPrimaryDisplayResolutionVertical','Census_OSInstallTypeName',
       'Census_PowerPlatformRoleName','Census_IsTouchEnabled',
       'Wdft_IsGamer']
dtypes = {}
for x in vv: dtypes[x] = 'category'
dtypes['MachineIdentifier'] = 'str'
dtypes['AvSigVersion'] = 'category'
dtypes['HasDetections'] = 'int8'

# LOAD CSV FILES
df_train = pd.read_csv('../input/microsoft-malware-prediction/train.csv', usecols=dtypes.keys(), dtype=dtypes)
print ('Loaded',len(df_train),'rows of TRAIN.CSV!')
df_test = pd.read_csv('../input/microsoft-malware-prediction/test.csv', usecols=list(dtypes.keys())[0:-1], dtype=dtypes)
print ('Loaded',len(df_test),'rows of TEST.CSV!')

# REDUCE SIZE FOR QUICKER PROTOTYPING
#df_train = df_train.sample(100000)
#df_test = df_test.sample(100000)
# IMPORT TIMESTAMP DICTIONARY
datedict = np.load('../input/malware-timestamps/AvSigVersionTimestamps.npy')
datedict = datedict[()]
# ADD TIMESTAMPS
df_train['Date'] = df_train['AvSigVersion'].map(datedict)
df_test['Date'] = df_test['AvSigVersion'].map(datedict)
import calendar, math

# PARAMETERS
# data : pandas.DataFrame : your data to plot
# col  : str : which column to plot histogram for left y-axis
# target : str : which column for mean/rate on right y-axis
# bars : int : how many histogram bars to show (or less if you set show or min)
# show : float : stop displaying bars after 100*show% of data is showing
# minn : float : don't display bars containing under 100*minn% of data
# sortby : str : either 'frequency', 'category', or 'rate'
# verbose : int : display text summary 1=yes, 0=no
# top : int : give this many bars nice color (and matches a subsequent dynamicPlot)
# title : str : title of plot
# asc : boolean : sort ascending (for category and rate)
# dropna : boolean : include missing data as a category or not

def staticPlot(data, col, target='HasDetections', bars=10, show=1.0, sortby='frequency'
               , verbose=1, top=5, title='',asc=False, dropna=False, minn=0.0):
    # calcuate density and detection rate
    cv = data[col].value_counts(dropna=dropna)
    cvd = cv.to_dict()
    nm = cv.index.values; lnn = len(nm); lnn2 = lnn
    th = show * len(data)
    th2 = minn * len(data)
    sum = 0; lnn2 = 0
    for x in nm[0:bars]:
        lnn2 += 1
        try: sum += cvd[x]
        except: sum += cv[x]
        if sum>th:
            break
        try:
            if cvd[x]<th2: break
        except:
            if cv[x]<th2: break
    if lnn2<bars: bars = lnn2
    pct = round(100.0*sum/len(data),2)
    lnn = min(lnn,lnn2)
    ratio = [0.0]*lnn; lnn3 = lnn
    if sortby =='frequency': lnn3 = min(lnn3,bars)
    elif sortby=='category': lnn3 = 0
    for i in range(lnn3):
        if target not in data:
            ratio[i] = np.nan
        elif nan_check(nm[i]):
            ratio[i] = data[target][data[col].isna()].mean()
        else:
            ratio[i] = data[target][data[col]==nm[i]].mean()
    try: all = pd.DataFrame( {'category':nm[0:lnn],'frequency':[cvd[x] for x in nm[0:lnn]],'rate':ratio} )
    except: all = pd.DataFrame( {'category':nm[0:lnn],'frequency':[cv[x] for x in nm[0:lnn]],'rate':ratio} )
    if sortby=='rate': 
        all = all.sort_values(sortby, ascending=asc)
    elif sortby=='category':
        try: 
            all['temp'] = all['category'].astype('float')
            all = all.sort_values('temp', ascending=asc)
        except:
            all = all.sort_values('category', ascending=asc)
    if bars<lnn: all = all[0:bars]
    if verbose==1 and target in data:
        print('TRAIN.CSV variable',col,'has',len(nm),'categories')
        print('The',min(bars,lnn),'bars displayed here contain',pct,'% of data.')
        mlnn = data[col].isna().sum()
        print("The data has %.1f %% NA. The plot is sorted by " % (100.0*mlnn/len(data)) + sortby )
    
    # plot density and detection rate
    fig = plt.figure(1,figsize=(15,3))
    ax1 = fig.add_subplot(1,1,1)
    clrs = ['red', 'green', 'blue', 'yellow', 'magenta']
    barss = ax1.bar([str(x) for x in all['category']],[x/float(len(data)) for x in all['frequency']],color=clrs)
    for i in range(len(all)-top):
        barss[top+i].set_color('cyan')
    if target in data:
        ax2 = ax1.twinx()
        if sortby!='category': infected = all['rate'][0:lnn]
        else:
            infected=[]
            for x in all['category']:
                if nan_check(x): infected.append( data[ data[col].isna() ][target].mean() )
                elif cvd[x]!=0: infected.append( data[ data[col]==x ][target].mean() )
                else: infected.append(-1)
        ax2.plot([str(x) for x in all['category']],infected[0:lnn],'k:o')
        #ax2.set_ylim(a,b)
        ax2.spines['left'].set_color('red')
        ax2.set_ylabel('Detection Rate', color='k')
    ax1.spines['left'].set_color('red')
    ax1.yaxis.label.set_color('red')
    ax1.tick_params(axis='y', colors='red')
    ax1.set_ylabel('Category Proportion', color='r')
    if title!='': plt.title(title)
    plt.show()
    if verbose==1 and target not in data:
        print('TEST.CSV variable',col,'has',len(nm),'categories')
        print('The',min(bars,lnn),'bars displayed here contain',pct,'% of the data.')
        mlnn = data[col].isna().sum()
        print("The data has %.1f %% NA. The plot is sorted by " % (100.0*mlnn/len(data)) + sortby )

# PARAMETERS
# data : pandas.DataFrame : your data to plot
# col  : str : which column for density on left y-axis
# target : str : which column for mean/rate on right y-axis
# start : datetime.datetime : x-axis minimum
# end : datetime.datetime : x-axis maximum
# inc_hr : int : resolution of time sampling = inc_hr + inc_dy*24 + inc_mn*720 hours
# inc_dy : int : resolution of time sampling = inc_hr + inc_dy*24 + inc_mn*720 hours
# inc_mn : int : resolution of time sampling = inc_hr + inc_dy*24 + inc_mn*720 hours
# show : float : only show the most frequent category values that include 100*show% of data
# top : int : plot this many solid lines
# top2 : int : plot this many dotted lines
# title : str : title of plot
# legend : int : include legend or not. 1=yes, 0=no
# dropna : boolean : include missing data as a category or not
        
def dynamicPlot(data,col, target='HasDetections', start=datetime(2018,4,1), end=datetime(2018,12,1)
                ,inc_hr=0,inc_dy=7,inc_mn=0,show=0.99,top=5,top2=4,title='',legend=1, dropna=False):
    # check for timestamps
    if 'Date' not in data:
        print('Error dynamicPlot: DataFrame needs column Date of datetimes')
        return
    
    # remove detection line if category density is too small
    cv = data[col].value_counts(dropna=dropna)
    cvd = cv.to_dict()
    nm = cv.index.values
    th = show * len(data)
    sum = 0; lnn2 = 0
    for x in nm:
        lnn2 += 1
        try: sum += cvd[x]
        except: sum += cv[x]
        if sum>th:
            break
    top = min(top,len(nm))
    top2 = min(top2,len(nm),lnn2,top)

    # calculate rate within each time interval
    diff = (end-start).days*24*3600 + (end-start).seconds
    size = diff//(3600*((inc_mn * 28 + inc_dy) * 24 + inc_hr)) + 5
    data_counts = np.zeros([size,2*top+1],dtype=float)
    idx=0; idx2 = {}
    for i in range(top):
        idx2[nm[i]] = i+1
    low = start
    high = add_time(start,inc_mn,inc_dy,inc_hr)
    data_times = [low+(high-low)/2]
    while low<end:
        slice = data[ (data['Date']<high) & (data['Date']>=low) ]
        data_counts[idx,0] = len(slice)
        for key in idx2:
            if nan_check(key): slice2 = slice[slice[col].isna()]
            else: slice2 = slice[slice[col]==key]
            data_counts[idx,idx2[key]] = len(slice2)
            if target in data:
                data_counts[idx,top+idx2[key]] = slice2['HasDetections'].mean()
        low = high
        high = add_time(high,inc_mn,inc_dy,inc_hr)
        data_times.append(low+(high-low)/2)
        idx += 1

    # plot lines
    fig = plt.figure(1,figsize=(15,3))
    cl = ['r','g','b','y','m']
    ax3 = fig.add_subplot(1,1,1)
    lines = []; labels = []
    for i in range(top):
        tmp, = ax3.plot(data_times,data_counts[0:idx+1,i+1],cl[i%5])
        lines.append(tmp)
        labels.append(str(nm[i]))
    ax3.spines['left'].set_color('red')
    ax3.yaxis.label.set_color('red')
    ax3.tick_params(axis='y', colors='red')
    if col!='ones': ax3.set_ylabel('Category Density', color='r')
    else: ax3.set_ylabel('Data Density', color='r')
    ax3.set_yticklabels([])
    if target in data:
        ax4 = ax3.twinx()
        for i in range(top2):
            ax4.plot(data_times,data_counts[0:idx+1,i+1+top],cl[i%5]+":")
        ax4.spines['left'].set_color('red')
        ax4.set_ylabel('Detection Rate', color='k')
    if title!='': plt.title(title)
    if legend==1: plt.legend(lines,labels)
    plt.show()
        
# INCREMENT A DATETIME
def add_time(sdate,months=0,days=0,hours=0):
    month = sdate.month -1 + months
    year = sdate.year + month // 12
    month = month % 12 + 1
    day = sdate.day + days
    if day>calendar.monthrange(year,month)[1]:
        day -= calendar.monthrange(year,month)[1]
        month += 1
        if month>12:
            month = 1
            year += 1
    hour = sdate.hour + hours
    if hour>23:
        hour = 0
        day += 1
        if day>calendar.monthrange(year,month)[1]:
            day -= calendar.monthrange(year,month)[1]
            month += 1
            if month>12:
                month = 1
                year += 1
    return datetime(year,month,day,hour,sdate.minute)

# CHECK FOR NAN
def nan_check(x):
    if isinstance(x,float):
        if math.isnan(x):
            return True
    return False
df_train['ones'] = 1; df_test['ones'] = 1
dynamicPlot(df_train,'ones',title='Train Data Density versus Time',legend=0)
dynamicPlot(df_test,'ones',title='Test Data Density versus Time',legend=0)
staticPlot(df_train,'SmartScreen',title='SmartScreen')
dynamicPlot(df_train,'SmartScreen',title='SmartScreen')
staticPlot(df_train,'AVProductsInstalled',title='AVProductsInstalled')
dynamicPlot(df_train,'AVProductsInstalled',title='AVProductsInstalled')
staticPlot(df_train,'CountryIdentifier',title='CountryIdentifier',bars=40,show=0.9)
dynamicPlot(df_train,'CountryIdentifier')
staticPlot(df_train,'CountryIdentifier',title='CountryIdentifier sorted by number',bars=40,show=0.9,sortby='category',verbose=0,asc=True)
staticPlot(df_train,'CountryIdentifier',title='CountryIdentifier sorted by decreasing rate',bars=40,show=0.9,sortby='rate',verbose=0)
staticPlot(df_train,'CountryIdentifier',title='CountryIdentifier sorted by increasing rate',bars=40,show=0.9,sortby='rate',verbose=0,asc=True)
dynamicPlot(df_train,'Census_OSVersion',title='TRAIN.CSV Census_OSVersion',show=0.99)
dynamicPlot(df_test,'Census_OSVersion',title='TEST.CSV Census_OSVersion',show=0.99)
# FEATURE ENGINEER - WEEK
first = datetime(2018,1,1); datedict2 = {}
for x in datedict: datedict2[x] = (datedict[x]-first).days//7
df_train['Week'] = df_train['AvSigVersion'].map(datedict2)
df_test['Week'] = df_test['AvSigVersion'].map(datedict2)

staticPlot(df_train,'Week',title='Week',show=0.99,asc=True,bars=25)
staticPlot(df_train,'Census_OSInstallTypeName',show=0.9,bars=50)
dynamicPlot(df_train,'Census_OSInstallTypeName')
staticPlot(df_train,'Census_TotalPhysicalRAM',title='99% of Census_TotalPhysicalRAM sorted by category',
           bars=155,sortby='category',show=0.99,dropna=True)
staticPlot(df_train,'Census_TotalPhysicalRAM',title='98% of Census_TotalPhysicalRAM sorted by category',
           bars=155,sortby='category',show=0.98,dropna=True,verbose=0)
# If you call encode_TE, encode_TE_partial, encode_FE_partial, 
# or encode_BE_partial on training data then the function 
# returns a 2 element python list containing [list, dictionary]
# the return[0] = list are the names of new columns added
# the return[1] = dictionary are which category variables got encoded
# When encoding test data after one of 4 calls above, use 'encode_?E_test'
# and pass the dictionary. If you don't use one of 4 above, then you can
# call basic 'encode_?E' on test.

# TARGET ENCODING
def encode_TE(df,col,tar='HasDetections'):
    d = {}
    v = df[col].unique()
    for x in v:
        if nan_check(x):
            m = df[tar][df[col].isna()].mean()
        else:
            m = df[tar][df[col]==x].mean()
        d[x] = m
    n = col+"_TE"
    df[n] = df[col].map(d)
    return [[n],d]

# TARGET ENCODING first ct columns by freq
def encode_TE_partial(df,col,ct,tar='HasDetections',xx=0.5):
    d = {}
    cv = df[col].value_counts(dropna=False)
    nm = cv.index.values[0:ct]
    for x in nm:
        if nan_check(x):
            m = df[tar][df[col].isna()].mean()
        else:
            m = df[tar][df[col]==x].mean()
        d[x] = m
    n = col+"_TE"
    df[n] = df[col].map(d).fillna(xx)
    return [[n],d]

# TARGET ENCODING from dictionary
def encode_TE_test(df,col,mp,xx=0.5):
    n = col+"_TE"
    df[n] = df[col].map(mp).fillna(xx)
    return [[n],0]

# FREQUENCY ENCODING
def encode_FE(df,col):
    d = df[col].value_counts(dropna=False)
    n = col+"_FE"
    df[n] = df[col].map(d)/d.max()
    return [[n],d]

# FREQUENCY ENCODING first ct columns by freq
def encode_FE_partial(df,col,ct):
    cv = df[col].value_counts(dropna=False)
    nm = cv.index.values[0:ct]
    n = col+"_FE"
    df[n] = df[col].map(cv)
    df.loc[~df[col].isin(nm),n] = np.mean(cv.values)
    df[n] = df[n] / max(cv.values)
    d = {}
    for x in nm: d[x] = cv[x]
    return [[n],d]

# FREQUENCY ENCODING from dictionary
def encode_FE_test(df,col,mp,xx=1.0):
    cv = df[col].value_counts(dropna=False)
    n = col+"_FE"
    df[n] = df[col].map(cv)
    df.loc[~df[col].isin(mp),n] = xx*np.mean(cv.values)
    df[n] = df[n] / max(cv.values)
    return [[n],mp]

# BINARY ENCODING
def encode_BE(df,col,val='xyz'):
    if val=='xyz':
        print('BE_encoding all')
        v = df[col].unique()
        n = []
        for x in v: n.append(encode_BE(df,col,x)[0][0])
        return [n,0]
    n = col+"_BE_"+str(val)
    if nan_check(val):
        df[n] = df[col].isna()
    elif isinstance(val, (list,)):
        if not isinstance(val[0], str):
            print('BE_encode Warning: val list not str')
        n = col+"_BE_"+str(val[0])+"_"+str(val[-1])
        d = {}
        for x in val: d[x]=1
        df[n] = df[col].map(d).fillna(0)
    else:
        if not isinstance(val, str):
            print('BE_encode Warning: val is not str')
        df[n] = df[col]==val
    df[n] = df[n].astype('int8')
    return [[n],0]

# BINARY ENCODING first ct columns by freq
def encode_BE_partial(df,col,ct):
    cv = df[col].value_counts(dropna=False)
    nm = cv.index.values[0:ct]
    d = {}
    n = []
    for x in nm: 
        n.append(encode_BE(df,col,x)[0][0])
        d[x] = 1
    return [n,d]

# BINARY ENCODING from dictionary
def encode_BE_test(df,col,mp):
    n = []
    for x in mp: n.append(encode_BE(df,col,x)[0][0])
    return [n,0]

# NUMERIC ENCODING
def encode_NE(df,col):
    n = col+"_NE"
    df[n] = df[col].astype(float)
    mx = np.std(df[n])
    mn = df[n].mean()
    df[n] = (df[n].fillna(mn) - mn) / mx
    return [[n],[mn,mx]]

# NUMERIC ENCODING from mean and std
def encode_NE_test(df,col,mm):
    n = col+"_NE"
    df[n] = df[col].astype(float)
    df[n] = (df[n].fillna(df[n].mean()) - mm[0]) / mm[1]
    return [[n],mm]
cols = []

# NUMERIC ENCODE
cols += encode_NE(df_train,'Census_TotalPhysicalRAM')[0]
cols += encode_NE(df_train,'AVProductsInstalled')[0]
cols += encode_NE(df_train,'Census_ProcessorCoreCount')[0]

# CATEGORY ENCODE for logistic regression
tmp = encode_BE_partial(df_train,'SmartScreen',5)
cols += tmp[0]; dict_smartscreen = tmp[1]
tmp = encode_BE_partial(df_train,'AVProductStatesIdentifier',5)
cols += tmp[0]; dict_productstate = tmp[1]

# BINARY ENCODE
cols += encode_BE(df_train,'Processor','x86')[0]
cols += encode_BE(df_train,'Census_IsTouchEnabled','1')[0]
cols += encode_BE(df_train,'Census_HasOpticalDiskDrive','1')[0]
cols += encode_BE(df_train,'Census_InternalPrimaryDisplayResolutionVertical',['800','600'])[0]
cols += encode_BE(df_train,'Census_PowerPlatformRoleName','Slate')[0]
cols += encode_BE(df_train,'Wdft_IsGamer','1')[0]

#FREQUENCY ENCODE
cols += encode_FE(df_train,'Census_ProcessorModelIdentifier')[0]
cols += encode_FE(df_train,'Week')[0]
#FREQUENCY ENCODE remove noise
tmp = encode_FE_partial(df_train,'Census_OSInstallTypeName',7)
cols += tmp[0]; dict_osinstalltype = tmp[1]

#TARGET ENCODE remove noise
tmp = encode_TE_partial(df_train,'CountryIdentifier',150)
cols += tmp[0]; dict_country = tmp[1]
tmp = encode_TE_partial(df_train,'OsBuild',5)
cols += tmp[0]; dict_osbuild = tmp[1]
import statsmodels.api as sm

logr = sm.Logit(df_train['HasDetections'], df_train[cols])
logr = logr.fit(disp=0)
df_train['Prob'] = logr.predict(df_train[cols])
print('Training complete')
#https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python
from sklearn import metrics
fpr, tpr, threshold = metrics.roc_curve(df_train['HasDetections'].values, df_train['Prob'].values)
roc_auc = metrics.auc(fpr, tpr)

# method I: plt
import matplotlib.pyplot as plt
plt.figure(figsize=(8,8))
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.3f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()
cols = []

# NUMERIC ENCODE
cols += encode_NE(df_test,'Census_TotalPhysicalRAM')[0]
cols += encode_NE(df_test,'AVProductsInstalled')[0]
cols += encode_NE(df_test,'Census_ProcessorCoreCount')[0]

# CATEGORY ENCODE for logistic regression
cols += encode_BE_test(df_test,'SmartScreen',dict_smartscreen)[0]
cols += encode_BE_test(df_test,'AVProductStatesIdentifier',dict_productstate)[0] 

# BINARY ENCODE
cols += encode_BE(df_test,'Processor','x86')[0]
cols += encode_BE(df_test,'Census_IsTouchEnabled','1')[0]
cols += encode_BE(df_test,'Census_HasOpticalDiskDrive','1')[0]
cols += encode_BE(df_test,'Census_InternalPrimaryDisplayResolutionVertical',['800','600'])[0]
cols += encode_BE(df_test,'Census_PowerPlatformRoleName','Slate')[0]
cols += encode_BE(df_test,'Wdft_IsGamer','1')[0]

# FREQUENCY ENCODE
cols += encode_FE(df_test,'Census_ProcessorModelIdentifier')[0]
cols += encode_FE(df_test,'Week')[0]
cols += encode_FE_test(df_test,'Census_OSInstallTypeName',dict_osinstalltype)[0]

# TARGET ENCODE
cols += encode_TE_test(df_test,'CountryIdentifier',dict_country)[0]
cols += encode_TE_test(df_test,'OsBuild',dict_osbuild)[0]
# PREDICT
df_test['HasDetections'] = logr.predict(df_test[cols])
# SUBMIT
df_test[['MachineIdentifier','HasDetections']].to_csv('submission.csv', index=False)
d = {}; 
for var in cols: d[var] = np.std(df_train[var])
importance = logr.params * pd.Series(d) * logr.pvalues.map(lambda x: 0 if x>=0.05 else 1)
order = importance.abs().sort_values(ascending = False)
importance[order.index]
var = ['Wdft_IsGamer','AVProductStatesIdentifier','Census_PowerPlatformRoleName','OsBuild',
       'Processor','Census_ProcessorCoreCount','Census_InternalPrimaryDisplayResolutionVertical',
       'Census_ProcessorModelIdentifier','Census_IsTouchEnabled','Census_HasOpticalDiskDrive']
bars = [2,20,10,5,10,3,10,20,10,10]
lines = [2,4,3,4,2,3,4,4,2,2]
for i in range(len(var)):
    staticPlot(df_train,var[i],show=0.99,bars=bars[i])
    dynamicPlot(df_train,var[i],top2=lines[i])
    corr = df_train[cols+['HasDetections']].corr()
    fig, ax = plt.subplots(figsize=(10,10))
    ax.matshow(corr)
    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90);
    plt.yticks(range(len(corr.columns)), corr.columns);