import numpy as np, pandas as pd, gc, random

import matplotlib.pyplot as plt



def load(x):

    ignore = ['MachineIdentifier']

    if x in ignore: return False

    else: return True



# LOAD TRAIN AND TEST

df_train = pd.read_csv('../input/microsoft-malware-prediction/train.csv',dtype='category',usecols=load)

df_train['HasDetections'] = df_train['HasDetections'].astype('int8')

if 5244810 in df_train.index:

    df_train.loc[5244810,'AvSigVersion'] = '1.273.1144.0'

    df_train['AvSigVersion'].cat.remove_categories('1.2&#x17;3.1144.0',inplace=True)

#df_train = df_train.sample(8000000).reset_index(drop=True)



df_test = pd.read_csv('../input/microsoft-malware-prediction/test.csv',dtype='category',usecols=load)

#df_test = df_test.sample(1000000).reset_index(drop=True)
# COMPARE VALUE DENSITIES FROM TWO DIFFERENT DATAFRAMES

#

# PARAMETERS

# df1: pandas.DataFrame containing variable

# df2: pandas.DataFrame containing variable

# col: column to compare between df1 and df2

# override: set to False to prevent display when variables similar

# verbose: display text summary

# scale: zooms y-axis

# title: plot title

# lab1: legend label for df1

# lab2: legend label for df2

# prefix: pre text for verbose summary

#

def comparePlot(df1, df2, col, factor=4, override=True, verbose=True, scale=0.5, title='',

                lab1='', lab2='', prefix=''):

    cv1 = pd.DataFrame(df1[col].value_counts(normalize=True).reset_index().rename({col:'train'},axis=1))

    cv2 = pd.DataFrame(df2[col].value_counts(normalize=True).reset_index().rename({col:'test'},axis=1))

    cv3 = pd.merge(cv1,cv2,on='index',how='outer')

    cv3['train'].fillna(0,inplace=True)

    cv3['test'].fillna(0,inplace=True)

    cv3 = cv3.iloc[np.lexsort((cv3['test'], -cv3['train']))]

    cv3['total'] = cv3['train']+cv3['test']

    cv3['trainMX'] = cv3['train']*factor

    cv3['trainMN'] = cv3['train']/factor

    cv3 = cv3[cv3['total']>0.0001]

    if (len(cv3)<5): return

    cv3.reset_index(inplace=True)

    MX = (cv3['test'] > cv3['trainMX'])

    mxSum = round(100*cv3.loc[MX,'test'].sum(),1)

    MN = (cv3['test'] < cv3['trainMN'])

    mnSum = round(100*cv3.loc[MN,'test'].sum(),1)

    #if override | (MX.sum()+MN.sum()>0):

    if override | (mxSum + mnSum > 1):

        plt.figure(figsize=(15,5))

        if lab1=='': lab1='Train'

        if lab2=='': lab2='Test'

        plt.plot(cv3.index,cv3['train'],linewidth=3,alpha=0.7,color='b',label=lab1)

        plt.plot(cv3.index,cv3['trainMX'],linewidth=2,alpha=1.0,linestyle=':',color='b',label=str())

        plt.plot(cv3.index,cv3['trainMN'],linewidth=2,alpha=1.0,linestyle=':',color='b',label=str())

        #plt.bar(cv3.index,cv3['test'],linewidth=3,alpha=0.7,color='g', label='Test.csv')

        plt.plot(cv3.index,cv3['test'],linewidth=3,alpha=0.7,color='g',label=lab2)

        plt.legend()

        if title=='': plt.title(col)

        else: plt.title(col+' - '+title)

        plt.xlabel(col+' values (ordered by train frequency and relabeled)')

        plt.ylabel('Frequency')

        mx = max(cv3['train'].max(),cv3['test'].max())

        #plt.ylim(0,mx*1.05)

        plt.ylim(0,mx*scale)

        plt.show()

        tempMX = cv3.loc[MX.values,['index','test']].sort_values('test',ascending=False)['index']

        tempMN = cv3.loc[MN.values,['index','test']].sort_values('test',ascending=False)['index']

        if verbose:

            if MX.sum()>0:    

                print(prefix+'Test.csv',col,'has',MX.sum(),'values 4x MORE freq than Train.csv. (',mxSum,'% of data)')

            if MX.sum()>10: print('  Top 10 by test freq:',list(tempMX)[:10])

            elif MX.sum()>0: print(list(tempMX)[:10])

            if MN.sum()>0:

                print(prefix+'Test.csv',col,'has',MN.sum(),'values 4x LESS freq than Train.csv. (',mnSum,'% of data)')

            if MN.sum()>10: print('  Top 10 by test freq:',list(tempMN)[:10])

            elif MN.sum()>0: print(list(tempMN)[:10])

    return
comparePlot(df_train, df_test, 'CountryIdentifier', verbose=False, title='Test vs. Train')
df_trainA = df_train.sample(frac=0.5)

df_trainB = df_train[ ~df_train.index.isin(df_trainA.index)]

comparePlot(df_trainA, df_trainB, 'CountryIdentifier', verbose=False,

            title='Random Validation Set vs. Train Subset', lab1='Train', lab2='Validation')
df_train['AvSigVersion2'] = df_train['AvSigVersion'].map(lambda x: np.int(x.split('.')[1]))

df_trainC = df_train[ df_train['AvSigVersion2']<275 ]

df_trainD = df_train[ df_train['AvSigVersion2']>=275 ]

comparePlot(df_trainC, df_trainD, 'CountryIdentifier', verbose=False,

            title='Time-split Validation vs. Train', lab1='Train', lab2='Validation')
from datetime import datetime

datedictAS = np.load('../input/malware-timestamps/AvSigVersionTimestamps.npy')[()]

df_train['DateAS'] = df_train['AvSigVersion'].map(datedictAS)

df_test['DateAS'] = df_test['AvSigVersion'].map(datedictAS)



df_testA = df_test[ df_test['DateAS']<datetime(2018,10,25) ]

df_testB = df_test[ df_test['DateAS']>datetime(2018,10,25) ]

comparePlot(df_train, df_testB, 'CountryIdentifier', verbose=False,

           title='Private Test vs. Train', lab1='Train', lab2='Private Test')

comparePlot(df_train, df_testA, 'CountryIdentifier', verbose=False,

           title='Public Test vs. Train', lab1='Train', lab2='Public Test')
# FACTORIZE DATA

def factor_data(df_train, df_test, col):

    df_comb = pd.concat([df_train[col],df_test[col]],axis=0)

    df_comb,_ = df_comb.factorize(sort=True)

    # MAKE SMALLEST LABEL 1, RESERVE 0

    df_comb += 1

    # MAKE NAN LARGEST LABEL

    df_comb = np.where(df_comb==0, df_comb.max()+1, df_comb)

    df_train[col] = df_comb[:len(df_train)]

    df_test[col] = df_comb[len(df_train):]

    del df_comb

    

# OPTIMIZE MEMORY

def reduce_memory(df,col):

    mx = df[col].max()

    if mx<256:

            df[col] = df[col].astype('uint8')

    elif mx<65536:

        df[col] = df[col].astype('uint16')

    else:

        df[col] = df[col].astype('uint32')



# REDUCE CATEGORY CARDINALITY

def relax_data(df_train, df_test, col):

    cv1 = pd.DataFrame(df_train[col].value_counts().reset_index().rename({col:'train'},axis=1))

    cv2 = pd.DataFrame(df_test[col].value_counts().reset_index().rename({col:'test'},axis=1))

    cv3 = pd.merge(cv1,cv2,on='index',how='outer')

    cv3['train'].fillna(0,inplace=True)

    cv3['test'].fillna(0,inplace=True)

    factor = len(df_test)/len(df_train)

    cv3['remove'] = False

    cv3['remove'] = cv3['remove'] | (cv3['train'] < len(df_train)/9000)

    cv3['remove'] = cv3['remove'] | (factor*cv3['train'] < cv3['test']/4)

    cv3['remove'] = cv3['remove'] | (factor*cv3['train'] > 4*cv3['test'])

    cv3['new'] = cv3.apply(lambda x: x['index'] if x['remove']==False else 0,axis=1)

    cv3['new'],_ = cv3['new'].factorize(sort=True)

    cv3.set_index('index',inplace=True)

    cc = cv3['new'].to_dict()

    df_train[col] = df_train[col].map(cc)

    reduce_memory(df_train,col)

    df_test[col] = df_test[col].map(cc)

    reduce_memory(df_test,col)

    

# DISPLAY MEMORY STATISTICS

def display_memory(df_train, df_test):

    print(len(df_train),'rows of training data use',df_train.memory_usage(deep=True).sum()//1e6,'Mb memory!')

    print(len(df_test),'rows of test data use',df_test.memory_usage(deep=True).sum()//1e6,'Mb memory!')



# CONVERT DTYPES TO CATEGORIES

def categorize(df_train, df_test, cols):

    for col in cols:

        df_train[col] = df_train[col].astype('category')

        df_test[col] = df_test[col].astype('category')
del df_trainA, df_trainB, df_trainC, df_trainD

del df_train['DateAS'], df_test['DateAS']; x=gc.collect()

cols = [x for x in df_train.columns if x not in ['HasDetections','AvSigVersion2']]

    

print('Factorizing...')

for col in cols: factor_data(df_train, df_test, col)

print('Reducing memory...')

for col in cols: reduce_memory(df_train, col)

for col in cols: reduce_memory(df_test, col)

categorize(df_train, df_test, cols)

display_memory(df_train, df_test)
import lightgbm as lgb

df_trainA = df_train.sample(frac=0.5)

df_trainB = df_train[ ~df_train.index.isin(df_trainA.index)]

model = lgb.LGBMClassifier(n_estimators=3000, colsample_bytree=0.2, objective='binary', num_leaves=16,

          max_depth=-1, learning_rate=0.1)

h=model.fit(df_trainA[cols], df_trainA['HasDetections'], eval_metric='auc',

          eval_set=[(df_trainB[cols], df_trainB['HasDetections'])], verbose=250,

          early_stopping_rounds=100)
del df_trainA, df_trainB; x=gc.collect()

idx = 0; chunk = 2000000

pred_val = np.zeros(len(df_test))

while idx < len(df_test):

    idx2 = min(idx + chunk, len(df_test) )

    idx = range(idx, idx2)

    pred_val[idx] = model.predict_proba(df_test.iloc[idx][cols])[:,1]

    idx = idx2

submit = pd.read_csv('../input/microsoft-malware-prediction/sample_submission.csv')

submit['HasDetections'] = pred_val

submit.to_csv('ModelOne.csv', index=False)
df_trainC = df_train[ df_train['AvSigVersion2']<275 ]

df_trainD = df_train[ df_train['AvSigVersion2']>=275 ]

model = lgb.LGBMClassifier(n_estimators=3000, colsample_bytree=0.2, objective='binary', num_leaves=16,

          max_depth=-1, learning_rate=0.1)

h=model.fit(df_trainC[cols], df_trainC['HasDetections'], eval_metric='auc',

          eval_set=[(df_trainD[cols], df_trainD['HasDetections'])], verbose=250,

          early_stopping_rounds=100)
print('Converting data to Model Two...')

df_trainC = df_trainC.copy()

df_trainD = df_trainD.copy()

for col in cols: relax_data(df_trainC, df_trainD, col)

categorize(df_trainC, df_trainD, cols)

model = lgb.LGBMClassifier(n_estimators=3000, colsample_bytree=0.2, objective='binary', num_leaves=16,

          max_depth=-1, learning_rate=0.1)

h=model.fit(df_trainC[cols], df_trainC['HasDetections'], eval_metric='auc',

          eval_set=[(df_trainD[cols], df_trainD['HasDetections'])], verbose=250,

          early_stopping_rounds=100)
print('Converting data to Model Two...')

del df_trainC, df_trainD; x=gc.collect()

for col in cols: relax_data(df_train, df_test, col)

categorize(df_train, df_test, cols)

df_trainA = df_train.sample(frac=0.5)

df_trainB = df_train[ ~df_train.index.isin(df_trainA.index)]

model = lgb.LGBMClassifier(n_estimators=3000, colsample_bytree=0.2, objective='binary', num_leaves=16,

          max_depth=-1, learning_rate=0.1)

h=model.fit(df_trainA[cols], df_trainA['HasDetections'], eval_metric='auc',

          eval_set=[(df_trainB[cols], df_trainB['HasDetections'])], verbose=250,

          early_stopping_rounds=100)
del df_trainA, df_trainB, df_train; x=gc.collect()

idx = 0; chunk = 2000000

pred_val = np.zeros(len(df_test))

while idx < len(df_test):

    idx2 = min(idx + chunk, len(df_test) )

    idx = range(idx, idx2)

    pred_val[idx] = model.predict_proba(df_test.iloc[idx][cols])[:,1]

    idx = idx2

submit = pd.read_csv('../input/microsoft-malware-prediction/sample_submission.csv')

submit['HasDetections'] = pred_val

submit.to_csv('ModelTwo.csv', index=False)
from sklearn.tree import DecisionTreeClassifier

from sklearn.metrics import roc_auc_score

from sklearn import tree

import graphviz



# LOAD TRAIN AND TEST

df_train = pd.read_csv('../input/microsoft-malware-prediction/train.csv',dtype='category',usecols=load, nrows=10000)

df_train['HasDetections'] = df_train['HasDetections'].astype('int8')

if 5244810 in df_train.index:

    df_train.loc[5244810,'AvSigVersion'] = '1.273.1144.0'

    df_train['AvSigVersion'].cat.remove_categories('1.2&#x17;3.1144.0',inplace=True)

#df_train = df_train.sample(1000000).reset_index(drop=True)

df_test = pd.read_csv('../input/microsoft-malware-prediction/test.csv',dtype='category',usecols=load, nrows=10000)

#df_test = df_test.sample(1000000).reset_index(drop=True)



# FACTORIZE

cols = [x for x in df_train.columns if x not in ['HasDetections','AvSigVersion2']]

for col in cols: factor_data(df_train, df_test, col)

for col in cols: reduce_memory(df_train, col)

for col in cols: reduce_memory(df_test, col)

categorize(df_train, df_test, cols)

# COMBINE TRAIN AND TEST

df_train['HasDetections'] = 0

df_test['HasDetections'] = 1

df_comb = pd.concat([df_train,df_test],axis=0)



# VALIDATION

model = DecisionTreeClassifier(max_leaf_nodes=5)

model.fit(df_comb[cols], df_comb['HasDetections'])

pred_val = model.predict_proba(df_comb[cols])[:,1]

print('Model One: Adversarial Training AUC = ',round( roc_auc_score(df_comb['HasDetections'],pred_val),4 ) )

#print('Adversarial Model has tree depth =',model.tree_.max_depth,'and node count =',model.tree_.node_count)

print('Adversarial Model has max_leaf_nodes=5')

# PLOT TREE                    

tree_graph = tree.export_graphviz(model, out_file=None, max_depth = 10,

        impurity = False, feature_names = cols, class_names = ['No', 'Yes'],

        rounded = True, filled= True )

graphviz.Source(tree_graph)
# CONVERT VARIABLES TO MODEL TWO

for col in cols: relax_data(df_train, df_test, col)

categorize(df_train, df_test, cols)

df_comb = pd.concat([df_train,df_test],axis=0)

# REMOVE TROUBLESOME SMODE

cols2 = cols.copy()

cols2.remove('SMode')



#VALIDATION

model = DecisionTreeClassifier(max_leaf_nodes=5)

model.fit(df_comb[cols2], df_comb['HasDetections'])

pred_val = model.predict_proba(df_comb[cols2])[:,1]

print('Model Two: Adversarial Training AUC = ',round( roc_auc_score(df_comb['HasDetections'],pred_val),4 ) )

#print('Adversarial Model has tree depth =',model.tree_.max_depth,'and node count =',model.tree_.node_count)

print('Adversarial Model has max_leaf_nodes=5')

# PLOT TREE          

tree_graph = tree.export_graphviz(model, out_file=None, max_depth = 10,

        impurity = False, feature_names = cols2, class_names = ['No', 'Yes'],

        rounded = True, filled= True )

graphviz.Source(tree_graph)
cols2 = {'AVProductStatesIdentifier':0.01, 'CountryIdentifier':0.4, 'LocaleEnglishNameIdentifier':0.3, 'SmartScreen':0.4,

         'Census_OEMNameIdentifier':0.1,'Census_TotalPhysicalRAM':0.5,'Census_InternalPrimaryDiagonalDisplaySizeInInches':0.05,

        'Census_OSInstallTypeName':0.75,'Census_OSInstallLanguageIdentifier':0.3,'Census_FirmwareManufacturerIdentifier':0.1,

        'EngineVersion':1.0, 'AppVersion':0.7, 'OsBuildLab':0.2, 'Census_OEMModelIdentifier':0.15,

        'Census_InternalBatteryNumberOfCharges':0.05}



df_train = pd.read_csv('../input/microsoft-malware-prediction/train.csv',dtype='category',usecols=load)

df_test = pd.read_csv('../input/microsoft-malware-prediction/test.csv',dtype='category',usecols=load)

df_test['DateAS'] = df_test['AvSigVersion'].map(datedictAS)

df_testA = df_test[ df_test['DateAS']<datetime(2018,10,25) ]

df_testB = df_test[ df_test['DateAS']>datetime(2018,10,25) ]



for x in df_train.columns[:-2]:

    s = 0.5

    if x in cols2: s = cols2[x] 

    comparePlot(df_train,df_testA,x,scale=s, title='Public Test vs. Train', prefix='Public ')

    comparePlot(df_train,df_testB,x,scale=s, title='Private Test vs. Train', prefix='Private ')